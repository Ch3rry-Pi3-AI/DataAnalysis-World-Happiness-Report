# Data Preprocessing â€“ Bronze -> Silver

This branch of the project is focused on **loading the bronze datasets** and **cleaning them** into the silver layer.
The following three datasets are cleaned individually in this stage, preparing them for merging in the upcoming feature engineering stage:

* World Happiness Report (multi-year)
* World Happiness Report 2021
* Geolocation Data (country codes, names, latitude, longitude)

The purpose of this stage is to ensure consistent column naming, add missing metadata (such as `year`), perform basic numeric imputations, and remove incomplete geolocation rows. The cleaned outputs are stored in the **silver** container for downstream use.

## Project Structure

The new modules are stored in `src/preprocess_data/`:

```
project-root/
â”œâ”€â”€ app.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ get_data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ import_happiness_data.py
â”‚   â”‚   â””â”€â”€ import_geolocation_data.py
â”‚   â”œâ”€â”€ preprocess_data/                    ðŸ†• (NEW)
â”‚   â”‚   â”œâ”€â”€ __init__.py                     ðŸ†•
â”‚   â”‚   â”œâ”€â”€ load_bronze_data.py             ðŸ†•
â”‚   â”‚   â””â”€â”€ clean_bronze_data.py            ðŸ†•
â””â”€â”€ data/
    â”œâ”€â”€ bronze/    
    â””â”€â”€ silver/    # cleaned outputs        ðŸ†•
```

* `load_bronze_data.py` -> Loads all bronze CSVs (multi-year, 2021, geolocation) into pandas DataFrames.
* `clean_bronze_data.py` -> Cleans each DataFrame (standardises columns, imputes missing values, validates coordinates, etc.) and saves them to the silver folder.
* `app.py` -> Updated to run the full pipeline: download bronze -> load bronze -> clean -> save silver.

## How to Run

You can run the preprocessing in three different ways depending on your workflow:

### 1) Run via the app entry point (recommended)

From the project root:

```bash
python app.py
```

This will:

* Download the bronze data if missing,
* Load all three bronze DataFrames,
* Clean them individually,
* Save the cleaned outputs into `data/silver/`.



### 2) Run the bronze loader directly

From the project root:

```bash
python -m src.preprocess_data.load_bronze_data
```

This will load all bronze CSVs and print quick summaries (row/column counts).



### 3) Run the bronze cleaner directly

From the project root:

```bash
python -m src.preprocess_data.clean_bronze_data
```

This will clean one or more of the bronze DataFrames and display before/after column names. When used through `app.py`, it will also save the cleaned versions into the silver folder.



## Output

* Cleaned silver CSVs will be stored under the `data/silver/` folder:

  * `world_happiness_multi_silver.csv`
  * `world_happiness_2021_silver.csv`
  * `geolocation_silver.csv`

* Logging confirms column standardisation, imputation, and geolocation validation.



## Notes

* These scripts are designed for the **silver stage** of the medallion architecture.
* Each dataset is cleaned **individually** in this stage. They will be merged together in the **feature engineering stage (gold)**.
* All modules follow the same style as earlier stages with docstrings, comments, and logging for clarity.

